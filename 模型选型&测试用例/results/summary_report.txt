================================================================================
儿童英语口语老师 Agent - 模型测试报告
================================================================================
测试时间: 2025-12-31T13:25:25.296923
测试用例数: 15

总体统计:
+------------+--------+--------+-----------+---------------+-------+-------+
| 模型         | 成功率    |   平均得分 |   平均延迟(s) |   首token延迟(s) |   成功数 |   失败数 |
+============+========+========+===========+===============+=======+=======+
| DeepSeek   | 100.0% |   7.53 |      2.26 |          1.03 |    15 |     0 |
+------------+--------+--------+-----------+---------------+-------+-------+
| Kimi       | 93.3%  |   7.7  |      1.65 |          0.99 |    14 |     1 |
+------------+--------+--------+-----------+---------------+-------+-------+
| 豆包         | 100.0% |   7.54 |      5.49 |          0.45 |    15 |     0 |
+------------+--------+--------+-----------+---------------+-------+-------+
| 通义千问-72B   | 100.0% |   7.59 |      3.74 |          0.86 |    15 |     0 |
+------------+--------+--------+-----------+---------------+-------+-------+
| 通义千问-Turbo | 100.0% |   7.74 |      1.63 |          0.8  |    15 |     0 |
+------------+--------+--------+-----------+---------------+-------+-------+

================================================================================
各维度详细评分
================================================================================

【语言能力】
+------------+--------------------------+-----------------------+--------------------------+------------------------------+-------+
| 模型         |   expression_naturalness |   grammar_correctness |   pronunciation_accuracy |   vocabulary_appropriateness |   平均分 |
+============+==========================+=======================+==========================+==============================+=======+
| DeepSeek   |                      8.5 |                     8 |                        7 |                         8.09 |  7.9  |
+------------+--------------------------+-----------------------+--------------------------+------------------------------+-------+
| Kimi       |                      8.5 |                     8 |                        7 |                         8.19 |  7.92 |
+------------+--------------------------+-----------------------+--------------------------+------------------------------+-------+
| 豆包         |                      8.5 |                     8 |                        7 |                         8.2  |  7.92 |
+------------+--------------------------+-----------------------+--------------------------+------------------------------+-------+
| 通义千问-72B   |                      8.5 |                     8 |                        7 |                         8.24 |  7.94 |
+------------+--------------------------+-----------------------+--------------------------+------------------------------+-------+
| 通义千问-Turbo |                      8.5 |                     8 |                        7 |                         8.13 |  7.91 |
+------------+--------------------------+-----------------------+--------------------------+------------------------------+-------+

【教学适配性】
+------------+---------------------------+--------------+-----------------------+-------------------+-------+
| 模型         |   child_friendly_language |   engagement |   interaction_quality |   personalization |   平均分 |
+============+===========================+==============+=======================+===================+=======+
| DeepSeek   |                      8.33 |         7.13 |                  8    |                 7 |  7.62 |
+------------+---------------------------+--------------+-----------------------+-------------------+-------+
| Kimi       |                      8.79 |         7.14 |                  8.14 |                 7 |  7.77 |
+------------+---------------------------+--------------+-----------------------+-------------------+-------+
| 豆包         |                      8.47 |         7.33 |                  8.07 |                 7 |  7.72 |
+------------+---------------------------+--------------+-----------------------+-------------------+-------+
| 通义千问-72B   |                      8.8  |         7.33 |                  8    |                 7 |  7.78 |
+------------+---------------------------+--------------+-----------------------+-------------------+-------+
| 通义千问-Turbo |                      8.73 |         7.33 |                  8.2  |                 7 |  7.82 |
+------------+---------------------------+--------------+-----------------------+-------------------+-------+

【响应性能】
+------------+-------------+-------+--------+------------+-------+
| 模型         |   stability |   总延迟 |   综合延迟 |   首token延迟 |   平均分 |
+============+=============+=======+========+============+=======+
| DeepSeek   |           7 |  6.13 |   6.69 |       6.93 |  6.69 |
+------------+-------------+-------+--------+------------+-------+
| Kimi       |           7 |  7.57 |   7.47 |       7.43 |  7.37 |
+------------+-------------+-------+--------+------------+-------+
| 豆包         |           7 |  3.33 |   7.16 |       8.8  |  6.57 |
+------------+-------------+-------+--------+------------+-------+
| 通义千问-72B   |           7 |  5.47 |   6.91 |       7.53 |  6.73 |
+------------+-------------+-------+--------+------------+-------+
| 通义千问-Turbo |           7 |  7.47 |   8.03 |       8.27 |  7.69 |
+------------+-------------+-------+--------+------------+-------+

【安全合规】
+------------+-----------------------+---------------------+-------+
| 模型         |   age_appropriateness |   content_filtering |   平均分 |
+============+=======================+=====================+=======+
| DeepSeek   |                  8.6  |                8.07 |  8.33 |
+------------+-----------------------+---------------------+-------+
| Kimi       |                  8.71 |                8.07 |  8.39 |
+------------+-----------------------+---------------------+-------+
| 豆包         |                  8.53 |                8.07 |  8.3  |
+------------+-----------------------+---------------------+-------+
| 通义千问-72B   |                  8.53 |                8.07 |  8.3  |
+------------+-----------------------+---------------------+-------+
| 通义千问-Turbo |                  8.6  |                8.07 |  8.33 |
+------------+-----------------------+---------------------+-------+

【成本效益】
+------------+------------+--------------------+-------+
| 模型         |   api_cost |   token_efficiency |   平均分 |
+============+============+====================+=======+
| DeepSeek   |          7 |                  5 |     6 |
+------------+------------+--------------------+-------+
| Kimi       |          7 |                  5 |     6 |
+------------+------------+--------------------+-------+
| 豆包         |          7 |                  5 |     6 |
+------------+------------+--------------------+-------+
| 通义千问-72B   |          7 |                  5 |     6 |
+------------+------------+--------------------+-------+
| 通义千问-Turbo |          7 |                  5 |     6 |
+------------+------------+--------------------+-------+

================================================================================
模型推荐
================================================================================
1. 通义千问-Turbo
   综合得分: 7.74/10
   平均延迟: 1.63s
   首token延迟: 0.80s

2. Kimi
   综合得分: 7.70/10
   平均延迟: 1.65s
   首token延迟: 0.99s

3. 通义千问-72B
   综合得分: 7.59/10
   平均延迟: 3.74s
   首token延迟: 0.86s

4. 豆包
   综合得分: 7.54/10
   平均延迟: 5.49s
   首token延迟: 0.45s

5. DeepSeek
   综合得分: 7.53/10
   平均延迟: 2.26s
   首token延迟: 1.03s
